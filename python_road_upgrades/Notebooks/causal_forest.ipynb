{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'econml'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-10-7654628b6638>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodel_selection\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtrain_test_split\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtree\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mDecisionTreeRegressor\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0meconml\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mortho_forest\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mContinuousTreatmentOrthoForest\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mCausalForest\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'econml'"
     ]
    }
   ],
   "source": [
    "# Use \"pip install econml\" on the command line to install the package\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from econml.ortho_forest import ContinuousTreatmentOrthoForest as CausalForest"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "     Unnamed: 0  county  year    crmrte    prbarr   prbconv   prbpris  avgsen  \\\n0             1       1    81  0.039885  0.289696  0.402062  0.472222    5.61   \n1             2       1    82  0.038345  0.338111  0.433005  0.506993    5.59   \n2             3       1    83  0.030305  0.330449  0.525703  0.479705    5.80   \n3             4       1    84  0.034726  0.362525  0.604706  0.520104    6.89   \n4             5       1    85  0.036573  0.325395  0.578723  0.497059    6.55   \n..          ...     ...   ...       ...       ...       ...       ...     ...   \n625         626     197    83  0.015575  0.226667  0.480392  0.428571    7.77   \n626         627     197    84  0.013662  0.204188  1.410260  0.372727   10.11   \n627         628     197    85  0.013086  0.180556  0.830769  0.333333    5.96   \n628         629     197    86  0.012874  0.112676  2.250000  0.244444    7.68   \n629         630     197    87  0.014193  0.207595  1.182930  0.360825   12.23   \n\n        polpc   density  ...       wtuc      wtrd      wfir      wser    wmfg  \\\n0    0.001787  2.307159  ...   333.6209  182.3330  272.4492  215.7335  229.12   \n1    0.001767  2.330254  ...   369.2964  189.5414  300.8788  231.5767  240.33   \n2    0.001836  2.341801  ...  1394.8030  196.6395  309.9696  240.1568  269.70   \n3    0.001886  2.346420  ...   398.8604  200.5629  350.0863  252.4477  281.74   \n4    0.001924  2.364896  ...   358.7830  206.8827  383.0707  261.0861  298.88   \n..        ...       ...  ...        ...       ...       ...       ...     ...   \n625  0.001073  0.869048  ...   317.9891  154.3210  254.8656  196.4637  256.19   \n626  0.001109  0.872024  ...   304.8781  170.5955  262.2378  192.6782  268.59   \n627  0.001054  0.875000  ...   283.4008  171.6738  271.7391  207.2574  279.17   \n628  0.001088  0.880952  ...   324.3744  180.0927  312.2946  215.2698  306.09   \n629  0.001186  0.889881  ...   341.8803  182.8020  348.1432  212.8205  322.92   \n\n       wfed    wsta    wloc       mix   pctymle  \n0    409.37  236.24  231.47  0.099918  0.087697  \n1    419.70  253.88  236.79  0.103049  0.086377  \n2    438.85  250.36  248.58  0.080679  0.085091  \n3    459.17  261.93  264.38  0.078504  0.083833  \n4    490.43  281.44  288.58  0.093249  0.082307  \n..      ...     ...     ...       ...       ...  \n625  352.65  345.27  235.90  0.113861  0.079020  \n626  345.90  354.21  246.89  0.116959  0.078233  \n627  357.84  354.78  275.01  0.081081  0.077222  \n628  376.54  355.64  294.49  0.075758  0.075701  \n629  391.72  385.65  306.85  0.067568  0.074199  \n\n[630 rows x 25 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>county</th>\n      <th>year</th>\n      <th>crmrte</th>\n      <th>prbarr</th>\n      <th>prbconv</th>\n      <th>prbpris</th>\n      <th>avgsen</th>\n      <th>polpc</th>\n      <th>density</th>\n      <th>...</th>\n      <th>wtuc</th>\n      <th>wtrd</th>\n      <th>wfir</th>\n      <th>wser</th>\n      <th>wmfg</th>\n      <th>wfed</th>\n      <th>wsta</th>\n      <th>wloc</th>\n      <th>mix</th>\n      <th>pctymle</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>81</td>\n      <td>0.039885</td>\n      <td>0.289696</td>\n      <td>0.402062</td>\n      <td>0.472222</td>\n      <td>5.61</td>\n      <td>0.001787</td>\n      <td>2.307159</td>\n      <td>...</td>\n      <td>333.6209</td>\n      <td>182.3330</td>\n      <td>272.4492</td>\n      <td>215.7335</td>\n      <td>229.12</td>\n      <td>409.37</td>\n      <td>236.24</td>\n      <td>231.47</td>\n      <td>0.099918</td>\n      <td>0.087697</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>82</td>\n      <td>0.038345</td>\n      <td>0.338111</td>\n      <td>0.433005</td>\n      <td>0.506993</td>\n      <td>5.59</td>\n      <td>0.001767</td>\n      <td>2.330254</td>\n      <td>...</td>\n      <td>369.2964</td>\n      <td>189.5414</td>\n      <td>300.8788</td>\n      <td>231.5767</td>\n      <td>240.33</td>\n      <td>419.70</td>\n      <td>253.88</td>\n      <td>236.79</td>\n      <td>0.103049</td>\n      <td>0.086377</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>83</td>\n      <td>0.030305</td>\n      <td>0.330449</td>\n      <td>0.525703</td>\n      <td>0.479705</td>\n      <td>5.80</td>\n      <td>0.001836</td>\n      <td>2.341801</td>\n      <td>...</td>\n      <td>1394.8030</td>\n      <td>196.6395</td>\n      <td>309.9696</td>\n      <td>240.1568</td>\n      <td>269.70</td>\n      <td>438.85</td>\n      <td>250.36</td>\n      <td>248.58</td>\n      <td>0.080679</td>\n      <td>0.085091</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>84</td>\n      <td>0.034726</td>\n      <td>0.362525</td>\n      <td>0.604706</td>\n      <td>0.520104</td>\n      <td>6.89</td>\n      <td>0.001886</td>\n      <td>2.346420</td>\n      <td>...</td>\n      <td>398.8604</td>\n      <td>200.5629</td>\n      <td>350.0863</td>\n      <td>252.4477</td>\n      <td>281.74</td>\n      <td>459.17</td>\n      <td>261.93</td>\n      <td>264.38</td>\n      <td>0.078504</td>\n      <td>0.083833</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>1</td>\n      <td>85</td>\n      <td>0.036573</td>\n      <td>0.325395</td>\n      <td>0.578723</td>\n      <td>0.497059</td>\n      <td>6.55</td>\n      <td>0.001924</td>\n      <td>2.364896</td>\n      <td>...</td>\n      <td>358.7830</td>\n      <td>206.8827</td>\n      <td>383.0707</td>\n      <td>261.0861</td>\n      <td>298.88</td>\n      <td>490.43</td>\n      <td>281.44</td>\n      <td>288.58</td>\n      <td>0.093249</td>\n      <td>0.082307</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>625</th>\n      <td>626</td>\n      <td>197</td>\n      <td>83</td>\n      <td>0.015575</td>\n      <td>0.226667</td>\n      <td>0.480392</td>\n      <td>0.428571</td>\n      <td>7.77</td>\n      <td>0.001073</td>\n      <td>0.869048</td>\n      <td>...</td>\n      <td>317.9891</td>\n      <td>154.3210</td>\n      <td>254.8656</td>\n      <td>196.4637</td>\n      <td>256.19</td>\n      <td>352.65</td>\n      <td>345.27</td>\n      <td>235.90</td>\n      <td>0.113861</td>\n      <td>0.079020</td>\n    </tr>\n    <tr>\n      <th>626</th>\n      <td>627</td>\n      <td>197</td>\n      <td>84</td>\n      <td>0.013662</td>\n      <td>0.204188</td>\n      <td>1.410260</td>\n      <td>0.372727</td>\n      <td>10.11</td>\n      <td>0.001109</td>\n      <td>0.872024</td>\n      <td>...</td>\n      <td>304.8781</td>\n      <td>170.5955</td>\n      <td>262.2378</td>\n      <td>192.6782</td>\n      <td>268.59</td>\n      <td>345.90</td>\n      <td>354.21</td>\n      <td>246.89</td>\n      <td>0.116959</td>\n      <td>0.078233</td>\n    </tr>\n    <tr>\n      <th>627</th>\n      <td>628</td>\n      <td>197</td>\n      <td>85</td>\n      <td>0.013086</td>\n      <td>0.180556</td>\n      <td>0.830769</td>\n      <td>0.333333</td>\n      <td>5.96</td>\n      <td>0.001054</td>\n      <td>0.875000</td>\n      <td>...</td>\n      <td>283.4008</td>\n      <td>171.6738</td>\n      <td>271.7391</td>\n      <td>207.2574</td>\n      <td>279.17</td>\n      <td>357.84</td>\n      <td>354.78</td>\n      <td>275.01</td>\n      <td>0.081081</td>\n      <td>0.077222</td>\n    </tr>\n    <tr>\n      <th>628</th>\n      <td>629</td>\n      <td>197</td>\n      <td>86</td>\n      <td>0.012874</td>\n      <td>0.112676</td>\n      <td>2.250000</td>\n      <td>0.244444</td>\n      <td>7.68</td>\n      <td>0.001088</td>\n      <td>0.880952</td>\n      <td>...</td>\n      <td>324.3744</td>\n      <td>180.0927</td>\n      <td>312.2946</td>\n      <td>215.2698</td>\n      <td>306.09</td>\n      <td>376.54</td>\n      <td>355.64</td>\n      <td>294.49</td>\n      <td>0.075758</td>\n      <td>0.075701</td>\n    </tr>\n    <tr>\n      <th>629</th>\n      <td>630</td>\n      <td>197</td>\n      <td>87</td>\n      <td>0.014193</td>\n      <td>0.207595</td>\n      <td>1.182930</td>\n      <td>0.360825</td>\n      <td>12.23</td>\n      <td>0.001186</td>\n      <td>0.889881</td>\n      <td>...</td>\n      <td>341.8803</td>\n      <td>182.8020</td>\n      <td>348.1432</td>\n      <td>212.8205</td>\n      <td>322.92</td>\n      <td>391.72</td>\n      <td>385.65</td>\n      <td>306.85</td>\n      <td>0.067568</td>\n      <td>0.074199</td>\n    </tr>\n  </tbody>\n</table>\n<p>630 rows × 25 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Crime.csv')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'econml'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-1-0bb06472463e>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmodel_selection\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtrain_test_split\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0msklearn\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtree\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mDecisionTreeRegressor\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 5\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0meconml\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mortho_forest\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mContinuousTreatmentOrthoForest\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mCausalForest\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      6\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[0mdf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'https://vincentarelbundock.github.io/Rdatasets/csv/Ecdat/Crime.csv'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'econml'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Set the categorical variables:\n",
    "cat_vars = ['year', 'region', 'smsa']\n",
    "# Transform the categorical variables to dummies and add them back in\n",
    "xf = pd.get_dummies(df[cat_vars])\n",
    "df = pd.concat([df.drop(cat_vars, axis=1), xf], axis=1)\n",
    "cat_var_dummy_names = list(xf.columns)\n",
    "\n",
    "regressors = ['prbarr', 'prbconv', 'prbpris',\n",
    "              'avgsen', 'polpc', 'density', 'taxpc',\n",
    "              'pctmin', 'wcon']\n",
    "# Add in the dummy names to the list of regressors\n",
    "regressors = regressors + cat_var_dummy_names\n",
    "\n",
    "# Split into train and test\n",
    "train, test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "# Estimate causal forest\n",
    "estimator = CausalForest(n_trees=100,\n",
    "                         model_T=DecisionTreeRegressor(),\n",
    "                         model_Y=DecisionTreeRegressor())\n",
    "estimator.fit(train['crmrte'],\n",
    "              train['pctymle'],\n",
    "              train[regressors],\n",
    "              inference='blb')\n",
    "effects_train = estimator.effect(train[regressors])\n",
    "effects_test = estimator.effect(test[regressors])\n",
    "conf_intrvl = estimator.effect_interval(test[regressors])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}