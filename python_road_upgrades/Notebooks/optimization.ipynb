{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# -------------- NESTED PATH CORRECTION -------------------------------- #\n",
    "\n",
    "# For all script files, we add the parent directory to the system path\n",
    "cwd = re.sub(r\"[\\\\]\", \"/\", os.getcwd())\n",
    "cwd_list = cwd.split(\"/\")\n",
    "path = sys.argv[0]\n",
    "path_list = path.split(\"/\")\n",
    "# either the entire filepath is entered as command i python\n",
    "if cwd_list[0:3] == path_list[0:3]:\n",
    "    full_path = path\n",
    "# or a relative path is entered, in which case we append the path to the cwd_path\n",
    "else:\n",
    "    full_path = cwd + \"/\" + path\n",
    "# remove the overlap\n",
    "root_dir = re.search(r\"(^.+python_road_upgrades)\", full_path).group(1)\n",
    "sys.path.append(root_dir)\n",
    "\n",
    "# ---------------------------------------------------------------------- #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def analyze_roads(pct):\n",
    "\n",
    "    def dummy_row_distance(df, dummy, agg_list):\n",
    "        if not isinstance(agg_list, list):\n",
    "            raise ValueError(\"agg_list argument needs to be a list\")\n",
    "        output_index = df.reset_index().set_index([('road', ''), ('subroad', '')])\n",
    "        filtered = df.loc[df[dummy] == 1,]\n",
    "        dist = filtered.reset_index().loc[:, [('road', ''), ('subroad', ''), ('id', '')]].groupby(['road', 'subroad']).diff().fillna(0).values\n",
    "        dist = pd.DataFrame(dist, index=filtered.index).reset_index().rename(columns={0: \"dist\"})\n",
    "        dist = dist.reset_index()#.group_by(['road', 'subroad'])\n",
    "        dist = dist.groupby(['road', 'subroad']).agg({'dist': agg_list})\n",
    "        dist = dist.reindex(df.index.droplevel(2).unique())\n",
    "        return dist\n",
    "\n",
    "    folder_name = \"composites_2\"        # directory should exist in Exports/Roads and Exports/Points\n",
    "\n",
    "\n",
    "    dir_roads = f\"{root_dir}/Exports/Roads/{folder_name}\"\n",
    "    dir_points = f\"{root_dir}/Exports/Points/{folder_name}\"\n",
    "\n",
    "    files_roads = os.listdir(dir_roads)\n",
    "    files_points = os.listdir(dir_points)\n",
    "\n",
    "\n",
    "    #for r in files_roads:\n",
    "    for r in [\"roads_2020_2021_05_07.xlsx\"]:\n",
    "        # r = \"roads_2020_2021_05_07.xlsx\"\n",
    "        if r[0:5] != 'roads':\n",
    "            continue\n",
    "        m = re.search(r\"roads_(\\d+)_(\\d+)_(\\d+)_(\\d+).xlsx\", r)\n",
    "        year1, year2, month1, month2 = m.group(1), m.group(2), m.group(3), m.group(4)\n",
    "\n",
    "        # load in the roads excel file\n",
    "        fp_r = f\"{dir_roads}/{r}\"\n",
    "        df_r = pd.read_excel(fp_r, engine='openpyxl')\n",
    "\n",
    "        # load in the csv points files and merge\n",
    "        df_p = pd.DataFrame()\n",
    "        for p in files_points:\n",
    "            if r[:-5] in p:\n",
    "                fp_p = f\"{dir_points}/{p}\"\n",
    "                imported = pd.read_csv(fp_p)\n",
    "                if df_p.empty:\n",
    "                    df_p = imported\n",
    "                else:\n",
    "                    df_p = pd.concat([df_p, imported])\n",
    "        df_p = df_p.sort_values(by=[\"road\", \"subroad\", \"type\", \"id\"])\n",
    "\n",
    "\n",
    "        # reshape\n",
    "        wide = pd.pivot_table(df_p, values=[\"B4_max\", \"B4_mean\", \"B4_min\", \"B8_max\", \"B8_mean\", \"B8_min\", \"B4_diff_factor\",\n",
    "                                            \"B8_diff_factor\" ], index=['road', 'subroad', 'id'], columns=['type'], aggfunc=np.sum)\n",
    "\n",
    "        # adjust for the diff factor\n",
    "        level1 = ['B4_max', 'B4_min', 'B4_mean', 'B8_max', 'B8_min', 'B8_mean']\n",
    "        level2 = ['road', 'left_25', 'left_50', 'left_75', 'right_25', 'right_50', 'right_75']\n",
    "        for l1 in level1:\n",
    "            if l1[0:2] == \"B4\":\n",
    "                diff_factor_array = wide.loc[:, ('B4_diff_factor', 'road')]\n",
    "            elif l1[0:2] == \"B8\":\n",
    "                diff_factor_array = wide.loc[:, ('B8_diff_factor', 'road')]\n",
    "            else:\n",
    "                raise ValueError(\"problem with diff factor adjustment\")\n",
    "            for l2 in level2:\n",
    "                wide[(l1, l2)] = wide[(l1, l2)] - diff_factor_array\n",
    "                #pass\n",
    "\n",
    "        # rewrite the sides as a difference from the road and\n",
    "        # create the averages\n",
    "        level1 = ['B4_max', 'B4_min', 'B4_mean', 'B8_max', 'B8_min', 'B8_mean']\n",
    "        for l1 in level1:\n",
    "            # make sides relative\n",
    "            # wide[[(l1, 'left_25'), (l1, 'left_50'), (l1, 'left_75')]] = wide[[(l1, 'left_25'), (l1, 'left_50'), (l1, 'left_75')]] - wide[[(l1, 'road')]].values\n",
    "            # create the averages\n",
    "            wide[(l1, 'left_avg')] =  wide[[(l1, 'left_25'), (l1, 'left_50'), (l1, 'left_75')]].mean(axis=1)\n",
    "            wide[(l1, 'right_avg')] =  wide[[(l1, 'right_25'), (l1, 'right_50'), (l1, 'right_75')]].mean(axis=1)\n",
    "\n",
    "\n",
    "        # thresholds, why not?\n",
    "        # compute upgraded points\n",
    "        thresholds = [50]\n",
    "\n",
    "        for thresh in thresholds:\n",
    "            level1 = ['B4_max', 'B8_max']\n",
    "            upg = f\"upg_{thresh}\"\n",
    "            for l1 in level1:\n",
    "                wide[(l1, upg)] = ( (wide[(l1, 'road')] > thresh) &\n",
    "                                    (wide[(l1, 'left_avg')] <= (pct/100) * wide[(l1, 'road')]) &\n",
    "                                    (wide[(l1, 'right_avg')] <= (pct/100) * wide[(l1, 'road')]) ).astype(int)\n",
    "            level1 = ['B4_min', 'B8_min']\n",
    "            for l1 in level1:\n",
    "                wide[(l1, upg)] = ( (wide[(l1, 'road')] < -thresh) &\n",
    "                                    (wide[(l1, 'left_avg')] >= (pct/100) * wide[(l1, 'road')]) &\n",
    "                                    (wide[(l1, 'right_avg')] >= (pct/100) * wide[(l1, 'road')]) ).astype(int)\n",
    "\n",
    "        upg_list = [f\"upg_{x}\" for x in thresholds]\n",
    "\n",
    "        # reorder columns\n",
    "        col_index_list = []\n",
    "        level1 = ['B4_max', 'B4_min', 'B4_mean', 'B8_max', 'B8_min', 'B8_mean', 'B4_diff_factor', 'B8_diff_factor']\n",
    "        level2 = upg_list+['road', 'left_avg', 'right_avg', 'left_25', 'left_50', 'left_75', 'right_25', 'right_50', 'right_75']\n",
    "        for l1 in level1:\n",
    "            for l2 in level2:\n",
    "                if l1 in ['B4_diff_factor', 'B8_diff_factor'] and l2 != \"road\":\n",
    "                    continue\n",
    "                col_index_list.append((l1, l2))\n",
    "        wide = wide.reindex(columns=col_index_list)\n",
    "\n",
    "        # clean up by dropping NaN columns\n",
    "        wide = wide.dropna(axis=1, how='all')\n",
    "\n",
    "\n",
    "\n",
    "        # compute the total count in each subroad\n",
    "        point_count = wide.reset_index().groupby(['road', 'subroad']).agg({('id', ''): 'count'}).values\n",
    "\n",
    "\n",
    "        # generate the tuples for aggregation\n",
    "        tup_dic = {}\n",
    "        for l1 in ['B4_max', 'B4_min', 'B4_mean', 'B8_max', 'B8_min', 'B8_mean']:\n",
    "            for l2 in ['road', 'left_avg', 'right_avg', f'upg_{thresholds[0]}']:\n",
    "                if (l1, l2) in list(wide.columns):\n",
    "                    tup_dic[(l1, l2)] = 'mean'\n",
    "                else:\n",
    "                    print(f\"skipping {(l1, l2)}\")\n",
    "\n",
    "        tup_dic[('B4_diff_factor', 'road')] = 'mean'\n",
    "        tup_dic[('B8_diff_factor', 'road')] = 'mean'\n",
    "\n",
    "        brightness = wide.reset_index().groupby(['road', 'subroad']).agg(tup_dic)\n",
    "\n",
    "        # rename the upg_0 to share\n",
    "        brightness = brightness.rename(columns={f'upg_{thresholds[0]}': \"share\"})\n",
    "\n",
    "\n",
    "        for l1 in ['B4_max', 'B4_min', 'B8_max', 'B8_min']:\n",
    "\n",
    "            # aggregate the road, left and right avg of upgraded roads only\n",
    "            upgraded_subset = wide.loc[wide[(l1, f'upg_{thresholds[0]}')] == 1, :]\n",
    "            tup_dic = {}\n",
    "            for l2 in ['road', 'left_avg', 'right_avg']:\n",
    "                tup_dic[(l1, l2)] = 'mean'\n",
    "            subset_aggs = upgraded_subset.reset_index().groupby(['road', 'subroad']).agg(tup_dic)\n",
    "            # apply the complete index\n",
    "            subset_aggs = subset_aggs.reindex(brightness.index)\n",
    "            # insert the new aggregations into the brightness df\n",
    "            col_id = list(brightness.columns).index((l1, 'right_avg'))\n",
    "            for c in list(reversed(list(subset_aggs.columns))):\n",
    "                brightness.insert((col_id + 1),(l1, f'{c[1]}_upg'), subset_aggs[c])\n",
    "\n",
    "            # get the id of the share\n",
    "            cols = list(brightness.columns)\n",
    "            col_id = cols.index((l1, 'share'))\n",
    "            dummy_aggs = ['median', 'mean']\n",
    "            dummy_vars = dummy_row_distance(wide, (l1, f'upg_{thresholds[0]}'), dummy_aggs)\n",
    "            for a in dummy_aggs:\n",
    "                buffer = dummy_aggs.index(a)\n",
    "                brightness.insert((col_id + buffer),(l1, f'dist_{a}'), dummy_vars[('dist', a)])\n",
    "\n",
    "        brightness = brightness.sort_values(by=('B4_min', 'road'), ascending=True)  # shows the percentage of points that meet condition\n",
    "        brightness = brightness.sort_index()\n",
    "\n",
    "\n",
    "        cols_before_dummies = list(brightness.columns)\n",
    "\n",
    "        # determine if the road is upgraded\n",
    "\n",
    "\n",
    "        brightness[('upgrade', \"bright_B4_diff\")] = ( (brightness[('B4_min', 'road')] < 0 ) &\n",
    "                                                      (brightness[('B4_min', 'left_avg')] > 0.75 * brightness[('B4_min', 'road')]) &\n",
    "                                                      (brightness[('B4_min', 'right_avg')] > 0.75 * brightness[('B4_min', 'road')]) #&\n",
    "                                                      #(brightness[('B4_min', 'left_avg')] > brightness[('B4_min', 'road')] + 50) &\n",
    "                                                      #(brightness[('B4_min', 'right_avg')] > brightness[('B4_min', 'road')] + 50)\n",
    "                                                      ).astype(int)\n",
    "\n",
    "\n",
    "        b4_diff_array = brightness[('B4_diff_factor', 'road')].values\n",
    "        brightness[('upgrade', \"bright_B4\")] = ( (brightness[('B4_min', 'road')] + b4_diff_array < 0 ) &\n",
    "                                                 (brightness[('B4_min', 'left_avg')] + b4_diff_array > 0.75 * (brightness[('B4_min', 'road')]+ b4_diff_array)) &\n",
    "                                                 (brightness[('B4_min', 'right_avg')] + b4_diff_array > 0.75 * (brightness[('B4_min', 'road')]+ b4_diff_array)) #&\n",
    "                                                 #(brightness[('B4_min', 'left_avg')] - b4_diff_array > brightness[('B4_min', 'road')] - b4_diff_array + 40) &\n",
    "                                                 #(brightness[('B4_min', 'right_avg')] - b4_diff_array > brightness[('B4_min', 'road')] - b4_diff_array + 40)\n",
    "                                                 ).astype(int)\n",
    "\n",
    "\n",
    "        cols = [('upgrade', \"bright_B4\"), ('upgrade', \"bright_B4_diff\")] + cols_before_dummies\n",
    "        brightness = brightness.loc[:, cols]\n",
    "\n",
    "        # add the values to the export sheet\n",
    "\n",
    "        brightness_results = brightness.reset_index().rename(columns={\"road\": \"road_id\", \"subroad\": \"subroad_id\"}).set_index(['road_id', 'subroad_id'])\n",
    "        #brightness_results\n",
    "\n",
    "        # x = df_r.set_index(['road_id', 'subroad_id'])\n",
    "        #\n",
    "        # x['upgraded'] = brightness_results[('upgrade', 'bright_B4_diff')]\n",
    "        # x['b_share_B4'] = brightness_results[('B4_min', 'road_id')]\n",
    "        # x['b_share_B4_left'] = brightness_results[('B4_min', 'left_avg')]\n",
    "        # x['b_share_B4_right'] = brightness_results[('B4_min', 'right_avg')]\n",
    "        #\n",
    "        # x = x.reset_index()\n",
    "\n",
    "\n",
    "        # export the brightness results (the analysis)\n",
    "        # EXPORT FILEPATH TO THE IMPORTS DIRECTORY\n",
    "        analysis_filename = r.replace('roads', 'analysis')\n",
    "        writer = pd.ExcelWriter(f\"{root_dir}/Exports/Roads/composites_2/{analysis_filename}\", engine='xlsxwriter', options={'strings_to_urls': False})\n",
    "        brightness_results.reset_index().to_excel(writer)\n",
    "        writer.close()\n",
    "\n",
    "        print(f\"HURRA! We finished spreadsheet {r}\")\n",
    "\n",
    "\n",
    "        #writer = pd.ExcelWriter(\"detailed_point_medians.xlsx\", engine='xlsxwriter', options={'strings_to_urls': False})\n",
    "        #brightness_results.reset_index().to_excel(writer)\n",
    "        #riter.close()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def get_regressors(df):\n",
    "    return df[[\n",
    "        ('B4_min', 'road_id'),\n",
    "        ('B4_min', 'left_avg'),\n",
    "        ('B4_min', 'right_avg'),\n",
    "        ('B4_mean', 'road_id'),\n",
    "        #('B4_mean', 'left_avg'),\n",
    "        #('B4_mean', 'right_avg'),\n",
    "        #('B4_min', 'dist_median'),\n",
    "        ('B4_min', 'dist_mean'),\n",
    "        ('B4_min', 'share'),\n",
    "        ('B4_diff_factor', 'road_id')\n",
    "\n",
    "    ]]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def eval_heuristic(fp, t_size):\n",
    "\n",
    "    # first the manual visual identifications (true values)\n",
    "    visual = pd.read_excel(f'{root_dir}/Imports/visual_classification_2020_2021_05_07.xlsx').set_index(['road_id', 'subroad_id'])\n",
    "    visual[visual['upgrade'] != 1] = 0  # replace unclear and NaN with 0\n",
    "\n",
    "    # followed by the analysis data\n",
    "    def import_analysis(data_fp):\n",
    "        data = pd.read_excel(data_fp,  header=[0,1], index_col=[0]).set_index(\n",
    "            [('road_id', 'Unnamed: 1_level_1'), ('subroad_id', 'Unnamed: 2_level_1')])\n",
    "        data.index.names = ['road_id', \"subroad_id\"]\n",
    "        data.columns.names = [None, None]\n",
    "        data = data.drop([('upgrade', 'bright_B4_diff'), ('upgrade', 'bright_B4')], axis=1)\n",
    "        return data\n",
    "\n",
    "    data = import_analysis(fp)\n",
    "\n",
    "    #print(data.columns)\n",
    "    # 1.2 Split the data into training and test sets\n",
    "\n",
    "\n",
    "    X = get_regressors(data)\n",
    "    y = visual['upgrade'].astype('int')  # Labels\n",
    "\n",
    "\n",
    "    # check for NaN and drop\n",
    "    nan_index = X[X.isnull().any(1)].index\n",
    "    X = X.drop(nan_index, axis=0)\n",
    "    y = y.drop(nan_index, axis=0)\n",
    "\n",
    "    # Split dataset into training set and test set\n",
    "    #     - argument test_size = 0.3: 70% training and 30% test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=t_size, random_state=5350)\n",
    "\n",
    "\n",
    "    # compute the optimal share threshold for the training data\n",
    "    accuracy_dic = {}\n",
    "    for t in range(0, 101):\n",
    "        share = t/100\n",
    "        h_pred = (\n",
    "            (X_train[('B4_min', 'share')] > share)\n",
    "        ).astype('int')\n",
    "        a = metrics.accuracy_score(y_train, h_pred)\n",
    "        if a not in list(accuracy_dic.keys()):\n",
    "            accuracy_dic[a] = [share]\n",
    "        else:\n",
    "            accuracy_dic[a].append(share)\n",
    "\n",
    "    max_key = max(list(accuracy_dic.keys()))\n",
    "    print(\"MAX ACCURACY FIT TRAINING DATA\", max_key)\n",
    "    print(\"THRESH IS\", accuracy_dic[max_key])\n",
    "\n",
    "    h_pred_share_test = (\n",
    "        (X_test[('B4_min', 'share')] > min(accuracy_dic[max_key]))\n",
    "    ).astype('int')\n",
    "\n",
    "\n",
    "    print(\"Heuristic Model Accuracy:\", metrics.accuracy_score(y_test, h_pred_share_test))\n",
    "    #print(\"Random Forest Model Accuracy:\", metrics.accuracy_score(y_test, h_pred))\n",
    "    return  metrics.accuracy_score(y_test, h_pred_share_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def train_model(t_size):\n",
    "    # 1. TRAIN THE RANDOM FOREST MODEL\n",
    "\n",
    "    # 1.1 Import the data sets\n",
    "\n",
    "    # first the manual visual identifications (true values)\n",
    "    visual = pd.read_excel(f'{root_dir}/Imports/visual_classification_2020_2021_05_07.xlsx').set_index(['road_id', 'subroad_id'])\n",
    "    visual[visual['upgrade'] != 1] = 0  # replace unclear and NaN with 0\n",
    "\n",
    "    # followed by the analysis data\n",
    "    def import_analysis(data_fp):\n",
    "        data = pd.read_excel(data_fp,  header=[0,1], index_col=[0]).set_index(\n",
    "            [('road_id', 'Unnamed: 1_level_1'), ('subroad_id', 'Unnamed: 2_level_1')])\n",
    "        data.index.names = ['road_id', \"subroad_id\"]\n",
    "        data.columns.names = [None, None]\n",
    "        data = data.drop([('upgrade', 'bright_B4_diff'), ('upgrade', 'bright_B4')], axis=1)\n",
    "        return data\n",
    "\n",
    "    data = import_analysis(data_fp)\n",
    "\n",
    "    X = get_regressors(data)\n",
    "    y = visual['upgrade'].astype('int')  # Labels\n",
    "\n",
    "    # check for NaN and drop\n",
    "    nan_index = X[X.isnull().any(1)].index\n",
    "    X = X.drop(nan_index, axis=0)\n",
    "    y = y.drop(nan_index, axis=0)\n",
    "\n",
    "    seed = 5350\n",
    "    # Split dataset into training set and test set\n",
    "    #     - argument test_size = 0.3: 70% training and 30% test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=t_size, random_state=seed)\n",
    "\n",
    "    ## HERE COMES THE OPTIMIZATION\n",
    "\n",
    "    # Create the parameter grid based on the results of random search\n",
    "    param_grid = {\n",
    "        'n_estimators': [20, 50, 100], # number of trees in the forest\n",
    "        'max_features': list(range(2, (len(list(get_regressors(X_train).columns))+1))),  # 7 features in the model 7+1 = 8\n",
    "        'max_depth': [20, 50, 100], # max number of levels in each tree\n",
    "        'bootstrap': [True, False],\n",
    "        'min_samples_leaf': [2, 4, 6],\n",
    "        'min_samples_split': [2, 3, 4],\n",
    "    }\n",
    "\n",
    "    rf = RandomForestClassifier(random_state=5350)\n",
    "\n",
    "    # Instantiate the grid search model\n",
    "    grid_search = GridSearchCV(estimator = rf, param_grid = param_grid,\n",
    "                               cv = 5, n_jobs = -1, verbose = 1)\n",
    "\n",
    "    # grid_search = RandomizedSearchCV(estimator = rf, param_distributions = param_grid,\n",
    "    #                                n_iter = 100, cv = 3, verbose=1, random_state=5350, n_jobs = -1)\n",
    "\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(grid_search.best_params_)\n",
    "    return grid_search.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "\n",
    "# results\n",
    "best_params = {'bootstrap': True, 'max_depth': 20, 'max_features': 5, 'min_samples_leaf': 6, 'min_samples_split': 2, 'n_estimators': 100}\n",
    "#train_model(0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def eval_model(fp, t_size):\n",
    "\n",
    "    # 1. TRAIN THE RANDOM FOREST MODEL\n",
    "\n",
    "    # 1.1 Import the data sets\n",
    "\n",
    "    # first the manual visual identifications (true values)\n",
    "    visual = pd.read_excel(f'{root_dir}/Imports/visual_classification_2020_2021_05_07.xlsx').set_index(['road_id', 'subroad_id'])\n",
    "    visual[visual['upgrade'] != 1] = 0  # replace unclear and NaN with 0\n",
    "\n",
    "    # followed by the analysis data\n",
    "    def import_analysis(data_fp):\n",
    "        data = pd.read_excel(data_fp,  header=[0,1], index_col=[0]).set_index(\n",
    "            [('road_id', 'Unnamed: 1_level_1'), ('subroad_id', 'Unnamed: 2_level_1')])\n",
    "        data.index.names = ['road_id', \"subroad_id\"]\n",
    "        data.columns.names = [None, None]\n",
    "        data = data.drop([('upgrade', 'bright_B4_diff'), ('upgrade', 'bright_B4')], axis=1)\n",
    "        return data\n",
    "\n",
    "\n",
    "    data = import_analysis(fp)\n",
    "\n",
    "\n",
    "    X = get_regressors(data)\n",
    "    y = visual['upgrade'].astype('int')  # Labels\n",
    "\n",
    "    # check for NaN and drop\n",
    "    nan_index = X[X.isnull().any(1)].index\n",
    "    X = X.drop(nan_index, axis=0)\n",
    "    y = y.drop(nan_index, axis=0)\n",
    "\n",
    "    seed = 5350\n",
    "    # Split dataset into training set and test set\n",
    "    #     - argument test_size = 0.3: 70% training and 30% test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=t_size, random_state=seed)\n",
    "\n",
    "\n",
    "    # Create a Gaussian Classifier\n",
    "    clf = RandomForestClassifier(**best_params, random_state=seed)\n",
    "\n",
    "\n",
    "    # Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"Random Forest Model Accuracy:\", metrics.accuracy_score(y_test, y_pred))\n",
    "    return metrics.accuracy_score(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "data_fp = f\"{root_dir}/Imports/analysis_2020_2021_05_07_pct_10.xlsx\" # a copy taken from Exports/Roads/composites2\n",
    "#eval_heuristic(data_fp, 0.1)\n",
    "#eval_model(data_fp, 0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping ('B4_mean', 'upg_50')\n",
      "skipping ('B8_mean', 'upg_50')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\generic.py:4153: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\generic.py:4153: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\generic.py:4153: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\generic.py:4153: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HURRA! We finished spreadsheet roads_2020_2021_05_07.xlsx\n",
      "Fitting 5 folds for each of 1134 candidates, totalling 5670 fits\n",
      "{'bootstrap': True, 'max_depth': 20, 'max_features': 8, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "MAX ACCURACY FIT TRAINING DATA 0.8266331658291457\n",
      "THRESH IS [0.09]\n",
      "Heuristic Model Accuracy: 0.8222222222222222\n",
      "Random Forest Model Accuracy: 0.9111111111111111\n",
      "COMPLETED 0\n",
      "skipping ('B4_mean', 'upg_50')\n",
      "skipping ('B8_mean', 'upg_50')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\generic.py:4153: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\generic.py:4153: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\generic.py:4153: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n",
      "C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\pandas\\core\\generic.py:4153: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HURRA! We finished spreadsheet roads_2020_2021_05_07.xlsx\n",
      "Fitting 5 folds for each of 1134 candidates, totalling 5670 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3427, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-9-b2040ea3879f>\", line 5, in <module>\n",
      "    best_params = train_model(0.1)\n",
      "  File \"<ipython-input-5-c5e648c2499e>\", line 55, in train_model\n",
      "    grid_search.fit(X_train, y_train)\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\sklearn\\model_selection\\_search.py\", line 841, in fit\n",
      "    self._run_search(evaluate_candidates)\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\sklearn\\model_selection\\_search.py\", line 1288, in _run_search\n",
      "    evaluate_candidates(ParameterGrid(self.param_grid))\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\sklearn\\model_selection\\_search.py\", line 795, in evaluate_candidates\n",
      "    out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\joblib\\parallel.py\", line 1054, in __call__\n",
      "    self.retrieve()\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\joblib\\parallel.py\", line 933, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 542, in wrap_future_result\n",
      "    return future.result(timeout=timeout)\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\concurrent\\futures\\_base.py\", line 434, in result\n",
      "    self._condition.wait(timeout)\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\threading.py\", line 302, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2054, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\inspect.py\", line 754, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\ntpath.py\", line 664, in realpath\n",
      "    if _getfinalpathname(spath) == path:\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3427, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-9-b2040ea3879f>\", line 5, in <module>\n",
      "    best_params = train_model(0.1)\n",
      "  File \"<ipython-input-5-c5e648c2499e>\", line 55, in train_model\n",
      "    grid_search.fit(X_train, y_train)\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\sklearn\\model_selection\\_search.py\", line 841, in fit\n",
      "    self._run_search(evaluate_candidates)\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\sklearn\\model_selection\\_search.py\", line 1288, in _run_search\n",
      "    evaluate_candidates(ParameterGrid(self.param_grid))\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\sklearn\\model_selection\\_search.py\", line 795, in evaluate_candidates\n",
      "    out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\joblib\\parallel.py\", line 1054, in __call__\n",
      "    self.retrieve()\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\joblib\\parallel.py\", line 933, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 542, in wrap_future_result\n",
      "    return future.result(timeout=timeout)\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\concurrent\\futures\\_base.py\", line 434, in result\n",
      "    self._condition.wait(timeout)\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\threading.py\", line 302, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2054, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3347, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2056, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1367, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1267, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1124, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2054, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\inspect.py\", line 754, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\ntpath.py\", line 647, in realpath\n",
      "    path = _getfinalpathname(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3427, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-9-b2040ea3879f>\", line 5, in <module>\n",
      "    best_params = train_model(0.1)\n",
      "  File \"<ipython-input-5-c5e648c2499e>\", line 55, in train_model\n",
      "    grid_search.fit(X_train, y_train)\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 63, in inner_f\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\sklearn\\model_selection\\_search.py\", line 841, in fit\n",
      "    self._run_search(evaluate_candidates)\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\sklearn\\model_selection\\_search.py\", line 1288, in _run_search\n",
      "    evaluate_candidates(ParameterGrid(self.param_grid))\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\sklearn\\model_selection\\_search.py\", line 795, in evaluate_candidates\n",
      "    out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\joblib\\parallel.py\", line 1054, in __call__\n",
      "    self.retrieve()\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\joblib\\parallel.py\", line 933, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 542, in wrap_future_result\n",
      "    return future.result(timeout=timeout)\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\concurrent\\futures\\_base.py\", line 434, in result\n",
      "    self._condition.wait(timeout)\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\threading.py\", line 302, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2054, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3347, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3444, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2056, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1367, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1267, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1124, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2054, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2932, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3155, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3366, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2056, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1367, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1267, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1142, in structured_traceback\n",
      "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2054, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\inspect.py\", line 754, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"C:\\Users\\Jeffrey\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\ntpath.py\", line 639, in realpath\n",
      "    cwd = os.getcwd()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output = []\n",
    "for thresh in list(np.array(range(0, 21))*5):\n",
    "    analyze_roads(thresh)\n",
    "    data_fp = f\"{root_dir}/Exports/Roads/composites_2/analysis_2020_2021_05_07.xlsx\"\n",
    "    best_params = train_model(0.1)\n",
    "    h = eval_heuristic(data_fp, 0.1)\n",
    "    m = eval_model(data_fp, 0.1)\n",
    "    output.append({'relative_thresh': thresh, 'heuristic': h, 'model': m, 'params': best_params})\n",
    "    print(\"COMPLETED\", thresh)\n",
    "df = pd.DataFrame(output)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-9-3fc184668200>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mdf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_excel\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'heuristic_optimization.xlsx'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mdf\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'df' is not defined"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 1147\n"
     ]
    }
   ],
   "source": [
    "df.to_excel('heuristic_optimization.xlsx')\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}